{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3076e4b-8554-443c-9b73-9df006ff1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03230930-57d0-46ea-ac76-befdd2f6c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = os.path.join(Path(os.getcwd()).resolve().parents[0] , \"local_only\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c4d3f7-c016-44a7-b543-a68e912c3e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/f/chatbot_ui_v4/local_only/data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234e914f-48d8-4f05-b655-6f0a8d87fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "DATASET_NAME = \"nlphuji/flickr30k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20c83a7-89b2-48a7-93c6-ac4e9883acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_flickr30k_dataset(dataset_name, download_location=None):\n",
    "    dataset = load_dataset(dataset_name, cache_dir=download_location)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aac12ed-6e9f-465b-b5dd-b7cf78c0d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = download_flickr30k_dataset(dataset_name = DATASET_NAME, download_location = CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5320fe-c6b0-4253-bc68-b7f78a9c46a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['image', 'caption', 'sentids', 'split', 'img_id', 'filename'],\n",
       "        num_rows: 31014\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15afb82c-d477-4217-aa3c-5d8d1a1197ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0138ac8-1e34-48e7-be6e-e850d8d7cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'caption', 'sentids', 'split', 'img_id', 'filename'],\n",
       "    num_rows: 31014\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c35fa3-39c2-4f23-9d4d-04edc0c2c4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=333x500>,\n",
       " 'caption': ['Two young guys with shaggy hair look at their hands while hanging out in the yard.',\n",
       "  'Two young, White males are outside near many bushes.',\n",
       "  'Two men in green shirts are standing in a yard.',\n",
       "  'A man in a blue shirt standing in a garden.',\n",
       "  'Two friends enjoy time spent together.'],\n",
       " 'sentids': ['0', '1', '2', '3', '4'],\n",
       " 'split': 'train',\n",
       " 'img_id': '0',\n",
       " 'filename': '1000092795.jpg'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc92d8de-168f-4824-99d3-cde3abac5bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x374>,\n",
       " 'caption': ['Several men in hard hats are operating a giant pulley system.',\n",
       "  'Workers look down from up above on a piece of equipment.',\n",
       "  'Two men working on a machine wearing hard hats.',\n",
       "  'Four men on top of a tall structure.',\n",
       "  'Three men on a large rig.'],\n",
       " 'sentids': ['5', '6', '7', '8', '9'],\n",
       " 'split': 'train',\n",
       " 'img_id': '1',\n",
       " 'filename': '10002456.jpg'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9eee9ab-3e81-42c5-99d6-9f4fb79199f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375>,\n",
       " 'caption': ['A man in shorts and a Hawaiian shirt leans over the rail of a pilot boat, with fog and mountains in the background.',\n",
       "  'A young man hanging over the side of a boat, which is in a like with fog rolling over a hill behind it.',\n",
       "  'A man is leaning off of the side of a blue and white boat as it sits in a body of water.',\n",
       "  'A man riding a small boat in a harbor, with fog and mountains in the background.',\n",
       "  'A man on a moored blue and white boat with hills and mist in the background.'],\n",
       " 'sentids': ['155065', '155066', '155067', '155068', '155069'],\n",
       " 'split': 'train',\n",
       " 'img_id': '31013',\n",
       " 'filename': '998845445.jpg'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50f05e6c-e3ce-4f42-a682-f98e87b113e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, ASCENDING, UpdateOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b292d203-8575-48bc-a14f-2d3514847e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mongo_db_client():\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    assert client.admin.command(\"ping\") == {'ok': 1.0}\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f81a034a-84c6-4a80-a6a9-fb4282c931bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client  = get_mongo_db_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44e7c929-4b83-4d61-aba7-0dcf4ed9df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'chatbot_ui_v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bc56cae-6120-4ef0-8482-fc678d5f2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLICKR:\n",
    "    def __init__(self, dataset_split):\n",
    "        self.dataset_split = dataset_split\n",
    "    def __iter__(self):\n",
    "        for record in self.dataset_split:\n",
    "            yield record\n",
    "    def batch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Yield records in batches of batch_size\n",
    "        \"\"\"\n",
    "        batch = []\n",
    "        for record in self:\n",
    "            batch.append(record)\n",
    "            if len(batch) >= batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        \n",
    "        if batch:\n",
    "            yield batch  # Yield remaining records if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49554fcb-a742-4aac-a182-3cdd3f24036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data_to_mongo_db(dataset):\n",
    "    mongo_db_client = get_mongo_db_client()\n",
    "    \n",
    "    database = mongo_db_client['chatbot_ui_v4']  \n",
    "\n",
    "    caption_collection = database['caption']\n",
    "    caption_collection.create_index([(\"sent_id\", ASCENDING)], unique=True)\n",
    "\n",
    "    #images_collection = database['images']\n",
    "    #images_collection.create_index([(\"img_id\", ASCENDING)], unique=True)\n",
    "\n",
    "    iterator = FLICKR(dataset)\n",
    "    print('Done with records:')\n",
    "    batch_size = 32\n",
    "    counter = 0\n",
    "    for batch in iterator.batch(batch_size=batch_size):\n",
    "        final_records = []\n",
    "        for record in batch:\n",
    "            to_append = [{'sent_id': sent_id, 'caption': caption} for sent_id, caption in zip(record['sentids'],record['caption'])]\n",
    "            to_append = [dict(**i, img_id=record['img_id'], filename = record['filename']) for i in to_append]\n",
    "            final_records.extend(to_append)\n",
    "        \n",
    "        records = [UpdateOne({'sent_id': i['sent_id']}, {'$set': i}, upsert=True) for i in final_records]\n",
    "        caption_collection.bulk_write(records)\n",
    "\n",
    "        counter+=batch_size\n",
    "        if counter % (10*batch_size) == 0:\n",
    "            print(counter, end='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "025f1cea-d37d-4470-80aa-52822a1042d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with records:\n",
      "320\t640\t960\t1280\t1600\t1920\t2240\t2560\t2880\t3200\t3520\t3840\t4160\t4480\t4800\t5120\t5440\t5760\t6080\t6400\t6720\t7040\t7360\t7680\t8000\t8320\t8640\t8960\t9280\t9600\t9920\t10240\t10560\t10880\t11200\t11520\t11840\t12160\t12480\t12800\t13120\t13440\t13760\t14080\t14400\t14720\t15040\t15360\t15680\t16000\t16320\t16640\t16960\t17280\t17600\t17920\t18240\t18560\t18880\t19200\t19520\t19840\t20160\t20480\t20800\t21120\t21440\t21760\t22080\t22400\t22720\t23040\t23360\t23680\t24000\t24320\t24640\t24960\t25280\t25600\t25920\t26240\t26560\t26880\t27200\t27520\t27840\t28160\t28480\t28800\t29120\t29440\t29760\t30080\t30400\t30720\t31040\tCPU times: user 42.6 s, sys: 107 ms, total: 42.7 s\n",
      "Wall time: 45.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = dataset['test']\n",
    "upload_data_to_mongo_db(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e47a6f7c-e9fb-46e2-851f-6222a87ef139",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_db_client = get_mongo_db_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "272aa1d7-be00-4b72-9850-00b81bc9b8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155070"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mongo_db_client['chatbot_ui_v4']['caption'].drop()\n",
    "collection = mongo_db_client['chatbot_ui_v4']['caption']\n",
    "collection.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e84b8801-febf-4c56-a9f4-b498714535e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('686b569ddc158f44299de34d'), 'sent_id': '0', 'caption': 'Two young guys with shaggy hair look at their hands while hanging out in the yard.', 'filename': '1000092795.jpg', 'img_id': '0'}\n",
      "{'_id': ObjectId('686b569ddc158f44299de34e'), 'sent_id': '1', 'caption': 'Two young, White males are outside near many bushes.', 'filename': '1000092795.jpg', 'img_id': '0'}\n"
     ]
    }
   ],
   "source": [
    "for i in collection.find().limit(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c26ba8d-dd4a-4af0-8d47-e54db611ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "\n",
    "class OpenCLIPEmbedder:\n",
    "    def __init__(self, model_name=\"ViT-L-14\", pretrained=\"laion2b_s32b_b82k\", device=None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model, _, self.preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained)\n",
    "        self.tokenizer = open_clip.get_tokenizer(model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    def encode_text(self, texts, normalize=True):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        tokens = self.tokenizer(texts).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            features = self.model.encode_text(tokens)\n",
    "        if normalize:\n",
    "            features /= features.norm(dim=-1, keepdim=True)\n",
    "        return features.cpu().numpy()\n",
    "    \n",
    "    def encode_image(self, images, normalize=True):\n",
    "        if isinstance(images, str):\n",
    "            images = [Image.open(images)]\n",
    "        elif isinstance(images, Image.Image):\n",
    "            images = [images]\n",
    "        \n",
    "        images = torch.stack([self.preprocess(img) for img in images]).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            features = self.model.encode_image(images)\n",
    "        if normalize:\n",
    "            features /= features.norm(dim=-1, keepdim=True)\n",
    "        return features.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ba600f5-9ebd-4ea6-b718-8c31bf8f5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DB_PORT = '8010'\n",
    "import chromadb\n",
    "def get_chroma_db_client():\n",
    "    client = chromadb.HttpClient(\n",
    "        host=\"localhost\",\n",
    "        port=int(CHROMA_DB_PORT))\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c970f27e-1c2c-4263-a4fa-f45678be9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data_to_chroma_db(dataset, embed_model):\n",
    "    vec_db_client = get_chroma_db_client()\n",
    "    \n",
    "    images_collection = vec_db_client.get_or_create_collection('images')\n",
    "\n",
    "    iterator = FLICKR(dataset)\n",
    "    print('Done with records:')\n",
    "    batch_size = 64\n",
    "    counter = 0\n",
    "    for batch in iterator.batch(batch_size=batch_size):\n",
    "        images = [i['image'] for i in batch]\n",
    "        \n",
    "        embeddings = embed_model.encode_image(images)\n",
    "        documents = [i['filename'] for i in batch]\n",
    "        ids = [i['img_id'] for i in batch]\n",
    "\n",
    "        to_upload = dict(documents=documents, embeddings=embeddings, ids=ids)\n",
    "        images_collection.add(**to_upload)\n",
    "        \n",
    "        counter+=batch_size\n",
    "        if counter % (10*batch_size) == 0:\n",
    "            print(counter, end='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aed2f5d3-d743-4932-8705-ba5730f1c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_db_client  = get_chroma_db_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab0e414e-f92e-47d6-8213-519aabb360ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenCLIPEmbedder(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0989f0a4-2dc6-4d61-a0b1-7fc05926df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with records:\n",
      "640\t1280\t1920\t2560\t3200\t3840\t4480\t5120\t5760\t6400\t7040\t7680\t8320\t8960\t9600\t10240\t10880\t11520\t12160\t12800\t13440\t14080\t14720\t15360\t16000\t16640\t17280\t17920\t18560\t19200\t19840\t20480\t21120\t21760\t22400\t23040\t23680\t24320\t24960\t25600\t26240\t26880\t27520\t28160\t28800\t29440\t30080\t30720\tCPU times: user 29min 21s, sys: 6.3 s, total: 29min 27s\n",
      "Wall time: 22min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "upload_data_to_chroma_db(dataset = dataset['test'], embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7619469d-bf75-4e2e-a6e1-6892de76344e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31014"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = vec_db_client.get_collection('images')\n",
    "col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15279905-8500-407e-9235-85eb35dba9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1a763-d953-47ac-b054-fd786c1a57a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9bf29-fdf0-40b4-a66c-34a212ce086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0ec1c-9bec-4ab1-8799-08c333498e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
